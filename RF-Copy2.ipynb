{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.grid_search as gs\n",
    "import sklearn.cross_validation as cv\n",
    "import sklearn.ensemble as ens\n",
    "import sklearn.metrics as mts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(0, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred/G_true\n",
    "\n",
    "scorer = mts.make_scorer(Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36132444808104458"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv', sep = ',', index_col = 'Id')\n",
    "test = pd.read_csv('./test.csv', sep = ',',index_col = 'Id')\n",
    "\n",
    "full = pd.concat(objs = [train, test])\n",
    "\n",
    "full.drop(['T1_V10', 'T1_V13','T2_V7', 'T2_V10'], axis=1, inplace = 1)\n",
    "\n",
    "num_mask = np.array([True if obj != 'object' else False for obj in full.dtypes])\n",
    "full_num = full.iloc[:,num_mask]\n",
    "full_cat = full.iloc[:, ~num_mask]\n",
    "cat_names = full_cat.columns\n",
    "form = ' + '.join(cat_names)\n",
    "form += ' - 1'\n",
    "x_dummies = patsy.dmatrix(form, full_cat, return_type='dataframe')\n",
    "full_dummies = pd.concat([full_num, x_dummies], axis = 1)\n",
    "train.shape, full_num.shape, full_cat.shape, x_dummies.shape, full_dummies.shape\n",
    "split = np.isnan(full_dummies.Hazard)\n",
    "train = full_dummies.loc[~split,:]\n",
    "test  = full_dummies.loc[split ,:]\n",
    "x = train.drop('Hazard', axis=1).values\n",
    "y = train.Hazard.values\n",
    "\n",
    "\n",
    "seed = 1\n",
    "\n",
    "mod_rf = ens.RandomForestRegressor(n_estimators = 30, random_state = seed, n_jobs = -1)\n",
    "\n",
    "params_rf = {'max_features': [38,40,42],\n",
    "             'min_samples_leaf': [8,9,10]}\n",
    "\n",
    "grid_rf = gs.GridSearchCV(mod_rf, param_grid=params_rf, n_jobs=-1, scoring = scorer, cv=5)\n",
    "\n",
    "grid_rf.fit(x,y)\n",
    "\n",
    "grid_rf.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
