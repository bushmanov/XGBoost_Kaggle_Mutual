{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gini(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(0, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return 'Gini', -G_pred/G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgboost_pred(train,labels,test):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"\n",
    "    params[\"eta\"] = 0.005\n",
    "    params[\"min_child_weight\"] = 5\n",
    "    params[\"subsample\"] = 0.6\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "    params[\"scale_pos_weight\"] = 1\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 9\n",
    "    plst = list(params.items())\n",
    "    \n",
    "    #Using 5000 rows for early stopping. \n",
    "    offset = 4000\n",
    "    num_rounds = 10000\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "    \n",
    "    #create a train and validation dmatrices \n",
    "    xgtrain = xgb.DMatrix(train[offset:,:], label=labels[offset:])\n",
    "    xgval = xgb.DMatrix(train[:offset,:], label=labels[:offset])\n",
    "    \n",
    "    #train using early stopping and predict\n",
    "    watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "    model = xgb.train(plst, xgtrain, num_rounds, watchlist, feval=Gini, early_stopping_rounds=120)\n",
    "    preds1 = model.predict(xgtest,ntree_limit=model.best_iteration)\n",
    "    \n",
    "    #reverse train and labels and use different 5k for early stopping. \n",
    "    # this adds very little to the score but it is an option if you are concerned about using all the data. \n",
    "    train = train[::-1,:]\n",
    "    labels = np.log(labels[::-1])\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(train[offset:,:], label=labels[offset:])\n",
    "    xgval = xgb.DMatrix(train[:offset,:], label=labels[:offset])\n",
    "    \n",
    "    watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "    model = xgb.train(plst, xgtrain, num_rounds, watchlist, feval=Gini, early_stopping_rounds=120)\n",
    "    preds2 = model.predict(xgtest,ntree_limit=model.best_iteration)\n",
    "    \n",
    "    #combine predictions\n",
    "    #since the metric only cares about relative rank we don't need to average\n",
    "    preds = (preds1)*1.4 + (preds2)*8.6\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load train and test \n",
    "train = pd.read_csv('./train.csv', index_col=0)\n",
    "test  = pd.read_csv('./test.csv', index_col=0)\n",
    "\n",
    "\n",
    "labels = train.Hazard\n",
    "train.drop('Hazard', axis=1, inplace=True)\n",
    "\n",
    "train_s = train\n",
    "test_s = test\n",
    "\n",
    "\n",
    "train_s.drop('T2_V10', axis=1, inplace=True)\n",
    "train_s.drop('T2_V7',  axis=1, inplace=True)\n",
    "train_s.drop('T1_V13', axis=1, inplace=True)\n",
    "train_s.drop('T1_V10', axis=1, inplace=True)\n",
    "\n",
    "test_s.drop('T2_V10', axis=1, inplace=True)\n",
    "test_s.drop('T2_V7',  axis=1, inplace=True)\n",
    "test_s.drop('T1_V13', axis=1, inplace=True)\n",
    "test_s.drop('T1_V10', axis=1, inplace=True)\n",
    "\n",
    "columns = train.columns\n",
    "test_ind = test.index\n",
    "\n",
    "train_s = np.array(train_s)\n",
    "test_s = np.array(test_s)\n",
    "\n",
    "# label encode the categorical variables\n",
    "for i in range(train_s.shape[1]):\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train_s[:,i]) + list(test_s[:,i]))\n",
    "    train_s[:,i] = lbl.transform(train_s[:,i])\n",
    "    test_s[:,i] = lbl.transform(test_s[:,i])\n",
    "\n",
    "train_s = train_s.astype(float)\n",
    "test_s = test_s.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until val error hasn't decreased in 120 rounds.\n",
      "[0]\ttrain-Gini:-0.327303\tval-Gini:-0.232757\n",
      "[1]\ttrain-Gini:-0.379422\tval-Gini:-0.285498\n",
      "[2]\ttrain-Gini:-0.399341\tval-Gini:-0.303596\n",
      "[3]\ttrain-Gini:-0.408209\tval-Gini:-0.313233\n",
      "[4]\ttrain-Gini:-0.412908\tval-Gini:-0.310595\n",
      "[5]\ttrain-Gini:-0.416414\tval-Gini:-0.315564\n",
      "[6]\ttrain-Gini:-0.419452\tval-Gini:-0.314876\n",
      "[7]\ttrain-Gini:-0.420400\tval-Gini:-0.320195\n",
      "[8]\ttrain-Gini:-0.422144\tval-Gini:-0.320789\n",
      "[9]\ttrain-Gini:-0.425029\tval-Gini:-0.320061\n",
      "[10]\ttrain-Gini:-0.424724\tval-Gini:-0.321595\n",
      "[11]\ttrain-Gini:-0.426171\tval-Gini:-0.323486\n",
      "[12]\ttrain-Gini:-0.425086\tval-Gini:-0.322965\n",
      "[13]\ttrain-Gini:-0.425662\tval-Gini:-0.323727\n",
      "[14]\ttrain-Gini:-0.425648\tval-Gini:-0.325262\n",
      "[15]\ttrain-Gini:-0.425756\tval-Gini:-0.325435\n",
      "[16]\ttrain-Gini:-0.425988\tval-Gini:-0.326691\n",
      "[17]\ttrain-Gini:-0.426454\tval-Gini:-0.326346\n",
      "[18]\ttrain-Gini:-0.426829\tval-Gini:-0.326804\n",
      "[19]\ttrain-Gini:-0.427205\tval-Gini:-0.327128\n",
      "[20]\ttrain-Gini:-0.430091\tval-Gini:-0.329668\n",
      "[21]\ttrain-Gini:-0.429791\tval-Gini:-0.329472\n",
      "[22]\ttrain-Gini:-0.430254\tval-Gini:-0.328310\n",
      "[23]\ttrain-Gini:-0.429737\tval-Gini:-0.328669\n",
      "[24]\ttrain-Gini:-0.430945\tval-Gini:-0.328397\n",
      "[25]\ttrain-Gini:-0.431319\tval-Gini:-0.329723\n",
      "[26]\ttrain-Gini:-0.431148\tval-Gini:-0.330394\n",
      "[27]\ttrain-Gini:-0.431867\tval-Gini:-0.330116\n",
      "[28]\ttrain-Gini:-0.433175\tval-Gini:-0.331253\n",
      "[29]\ttrain-Gini:-0.433461\tval-Gini:-0.331412\n",
      "[30]\ttrain-Gini:-0.433969\tval-Gini:-0.330587\n",
      "[31]\ttrain-Gini:-0.433921\tval-Gini:-0.330971\n",
      "[32]\ttrain-Gini:-0.434852\tval-Gini:-0.331273\n",
      "[33]\ttrain-Gini:-0.434694\tval-Gini:-0.331530\n",
      "[34]\ttrain-Gini:-0.435847\tval-Gini:-0.332536\n",
      "[35]\ttrain-Gini:-0.435821\tval-Gini:-0.333407\n",
      "[36]\ttrain-Gini:-0.435211\tval-Gini:-0.332838\n",
      "[37]\ttrain-Gini:-0.435617\tval-Gini:-0.332911\n",
      "[38]\ttrain-Gini:-0.435398\tval-Gini:-0.332972\n",
      "[39]\ttrain-Gini:-0.435616\tval-Gini:-0.333322\n",
      "[40]\ttrain-Gini:-0.436058\tval-Gini:-0.332681\n",
      "[41]\ttrain-Gini:-0.436517\tval-Gini:-0.333190\n",
      "[42]\ttrain-Gini:-0.436508\tval-Gini:-0.333760\n",
      "[43]\ttrain-Gini:-0.436568\tval-Gini:-0.334246\n",
      "[44]\ttrain-Gini:-0.436931\tval-Gini:-0.334851\n",
      "[45]\ttrain-Gini:-0.437374\tval-Gini:-0.335318\n",
      "[46]\ttrain-Gini:-0.437533\tval-Gini:-0.335278\n",
      "[47]\ttrain-Gini:-0.438061\tval-Gini:-0.335529\n",
      "[48]\ttrain-Gini:-0.438347\tval-Gini:-0.335829\n",
      "[49]\ttrain-Gini:-0.438699\tval-Gini:-0.336151\n",
      "[50]\ttrain-Gini:-0.439085\tval-Gini:-0.336219\n",
      "[51]\ttrain-Gini:-0.439648\tval-Gini:-0.336784\n",
      "[52]\ttrain-Gini:-0.439938\tval-Gini:-0.337115\n",
      "[53]\ttrain-Gini:-0.440083\tval-Gini:-0.337412\n",
      "[54]\ttrain-Gini:-0.440137\tval-Gini:-0.337603\n",
      "[55]\ttrain-Gini:-0.440253\tval-Gini:-0.337974\n",
      "[56]\ttrain-Gini:-0.440187\tval-Gini:-0.337483\n",
      "[57]\ttrain-Gini:-0.440375\tval-Gini:-0.337783\n",
      "[58]\ttrain-Gini:-0.440529\tval-Gini:-0.337978\n",
      "[59]\ttrain-Gini:-0.440564\tval-Gini:-0.338211\n",
      "[60]\ttrain-Gini:-0.440519\tval-Gini:-0.337843\n",
      "[61]\ttrain-Gini:-0.440911\tval-Gini:-0.338556\n",
      "[62]\ttrain-Gini:-0.441114\tval-Gini:-0.338511\n",
      "[63]\ttrain-Gini:-0.441457\tval-Gini:-0.338712\n",
      "[64]\ttrain-Gini:-0.441214\tval-Gini:-0.338628\n",
      "[65]\ttrain-Gini:-0.441389\tval-Gini:-0.338388\n",
      "[66]\ttrain-Gini:-0.441675\tval-Gini:-0.338883\n",
      "[67]\ttrain-Gini:-0.441921\tval-Gini:-0.339224\n",
      "[68]\ttrain-Gini:-0.441949\tval-Gini:-0.339073\n",
      "[69]\ttrain-Gini:-0.442166\tval-Gini:-0.338970\n",
      "[70]\ttrain-Gini:-0.442308\tval-Gini:-0.338806\n",
      "[71]\ttrain-Gini:-0.442268\tval-Gini:-0.338829\n",
      "[72]\ttrain-Gini:-0.442579\tval-Gini:-0.338859\n",
      "[73]\ttrain-Gini:-0.442603\tval-Gini:-0.338989\n",
      "[74]\ttrain-Gini:-0.442726\tval-Gini:-0.338883\n",
      "[75]\ttrain-Gini:-0.442758\tval-Gini:-0.338889\n",
      "[76]\ttrain-Gini:-0.442892\tval-Gini:-0.338275\n",
      "[77]\ttrain-Gini:-0.443398\tval-Gini:-0.338572\n",
      "[78]\ttrain-Gini:-0.443467\tval-Gini:-0.338859\n",
      "[79]\ttrain-Gini:-0.443506\tval-Gini:-0.338952\n",
      "[80]\ttrain-Gini:-0.443541\tval-Gini:-0.338595\n",
      "[81]\ttrain-Gini:-0.443662\tval-Gini:-0.338707\n",
      "[82]\ttrain-Gini:-0.443559\tval-Gini:-0.338733\n",
      "[83]\ttrain-Gini:-0.443734\tval-Gini:-0.339066\n",
      "[84]\ttrain-Gini:-0.443926\tval-Gini:-0.338915\n",
      "[85]\ttrain-Gini:-0.444018\tval-Gini:-0.339198\n",
      "[86]\ttrain-Gini:-0.444047\tval-Gini:-0.339240\n",
      "[87]\ttrain-Gini:-0.444280\tval-Gini:-0.339202\n",
      "[88]\ttrain-Gini:-0.444485\tval-Gini:-0.339421\n",
      "[89]\ttrain-Gini:-0.444704\tval-Gini:-0.339780\n",
      "[90]\ttrain-Gini:-0.444824\tval-Gini:-0.339859\n",
      "[91]\ttrain-Gini:-0.445079\tval-Gini:-0.340075\n",
      "[92]\ttrain-Gini:-0.445376\tval-Gini:-0.340350\n",
      "[93]\ttrain-Gini:-0.445549\tval-Gini:-0.340977\n",
      "[94]\ttrain-Gini:-0.445596\tval-Gini:-0.340938\n",
      "[95]\ttrain-Gini:-0.445786\tval-Gini:-0.341163\n",
      "[96]\ttrain-Gini:-0.445886\tval-Gini:-0.340955\n",
      "[97]\ttrain-Gini:-0.446400\tval-Gini:-0.340834\n",
      "[98]\ttrain-Gini:-0.446443\tval-Gini:-0.340947\n",
      "[99]\ttrain-Gini:-0.446794\tval-Gini:-0.341370\n",
      "[100]\ttrain-Gini:-0.446842\tval-Gini:-0.341141\n",
      "[101]\ttrain-Gini:-0.447081\tval-Gini:-0.341172\n",
      "[102]\ttrain-Gini:-0.447257\tval-Gini:-0.341233\n",
      "[103]\ttrain-Gini:-0.447463\tval-Gini:-0.341265\n",
      "[104]\ttrain-Gini:-0.447478\tval-Gini:-0.341091\n",
      "[105]\ttrain-Gini:-0.447836\tval-Gini:-0.341451\n",
      "[106]\ttrain-Gini:-0.447888\tval-Gini:-0.341445\n",
      "[107]\ttrain-Gini:-0.447925\tval-Gini:-0.341573\n",
      "[108]\ttrain-Gini:-0.448197\tval-Gini:-0.341478\n",
      "[109]\ttrain-Gini:-0.448343\tval-Gini:-0.341619\n",
      "[110]\ttrain-Gini:-0.448684\tval-Gini:-0.341800\n",
      "[111]\ttrain-Gini:-0.448766\tval-Gini:-0.342125\n",
      "[112]\ttrain-Gini:-0.448926\tval-Gini:-0.342107\n",
      "[113]\ttrain-Gini:-0.449101\tval-Gini:-0.341989\n",
      "[114]\ttrain-Gini:-0.449116\tval-Gini:-0.341983\n",
      "[115]\ttrain-Gini:-0.449385\tval-Gini:-0.342075\n",
      "[116]\ttrain-Gini:-0.449654\tval-Gini:-0.342144\n",
      "[117]\ttrain-Gini:-0.449799\tval-Gini:-0.342227\n",
      "[118]\ttrain-Gini:-0.450239\tval-Gini:-0.342491\n",
      "[119]\ttrain-Gini:-0.450293\tval-Gini:-0.342356\n",
      "[120]\ttrain-Gini:-0.450410\tval-Gini:-0.342771\n",
      "[121]\ttrain-Gini:-0.450561\tval-Gini:-0.342929\n",
      "[122]\ttrain-Gini:-0.450706\tval-Gini:-0.342843\n",
      "[123]\ttrain-Gini:-0.450720\tval-Gini:-0.342743\n",
      "[124]\ttrain-Gini:-0.450952\tval-Gini:-0.343010\n",
      "[125]\ttrain-Gini:-0.451101\tval-Gini:-0.343233\n",
      "[126]\ttrain-Gini:-0.451242\tval-Gini:-0.343157\n",
      "[127]\ttrain-Gini:-0.451451\tval-Gini:-0.342900\n",
      "[128]\ttrain-Gini:-0.451449\tval-Gini:-0.342830\n",
      "[129]\ttrain-Gini:-0.451609\tval-Gini:-0.343125\n",
      "[130]\ttrain-Gini:-0.451848\tval-Gini:-0.343159\n",
      "[131]\ttrain-Gini:-0.451998\tval-Gini:-0.343475\n",
      "[132]\ttrain-Gini:-0.452301\tval-Gini:-0.343576\n",
      "[133]\ttrain-Gini:-0.452491\tval-Gini:-0.343616\n",
      "[134]\ttrain-Gini:-0.452562\tval-Gini:-0.343613\n",
      "[135]\ttrain-Gini:-0.452793\tval-Gini:-0.343490\n",
      "[136]\ttrain-Gini:-0.452908\tval-Gini:-0.343487\n",
      "[137]\ttrain-Gini:-0.453293\tval-Gini:-0.343495\n",
      "[138]\ttrain-Gini:-0.453208\tval-Gini:-0.343356\n",
      "[139]\ttrain-Gini:-0.453473\tval-Gini:-0.343512\n",
      "[140]\ttrain-Gini:-0.453678\tval-Gini:-0.343516\n",
      "[141]\ttrain-Gini:-0.453883\tval-Gini:-0.343574\n",
      "[142]\ttrain-Gini:-0.454007\tval-Gini:-0.344030\n",
      "[143]\ttrain-Gini:-0.454215\tval-Gini:-0.343991\n",
      "[144]\ttrain-Gini:-0.454310\tval-Gini:-0.344007\n",
      "[145]\ttrain-Gini:-0.454486\tval-Gini:-0.344180\n",
      "[146]\ttrain-Gini:-0.454657\tval-Gini:-0.344441\n",
      "[147]\ttrain-Gini:-0.454953\tval-Gini:-0.344732\n",
      "[148]\ttrain-Gini:-0.454984\tval-Gini:-0.344674\n",
      "[149]\ttrain-Gini:-0.455001\tval-Gini:-0.344577\n",
      "[150]\ttrain-Gini:-0.455144\tval-Gini:-0.344839\n",
      "[151]\ttrain-Gini:-0.455263\tval-Gini:-0.344818\n",
      "[152]\ttrain-Gini:-0.455438\tval-Gini:-0.344875\n",
      "[153]\ttrain-Gini:-0.455481\tval-Gini:-0.344954\n",
      "[154]\ttrain-Gini:-0.455707\tval-Gini:-0.345048\n",
      "[155]\ttrain-Gini:-0.455718\tval-Gini:-0.345151\n",
      "[156]\ttrain-Gini:-0.455812\tval-Gini:-0.345182\n",
      "[157]\ttrain-Gini:-0.455950\tval-Gini:-0.345292\n",
      "[158]\ttrain-Gini:-0.456173\tval-Gini:-0.345257\n",
      "[159]\ttrain-Gini:-0.456350\tval-Gini:-0.345284\n",
      "[160]\ttrain-Gini:-0.456578\tval-Gini:-0.345422\n",
      "[161]\ttrain-Gini:-0.456567\tval-Gini:-0.345359\n",
      "[162]\ttrain-Gini:-0.456795\tval-Gini:-0.345623\n",
      "[163]\ttrain-Gini:-0.457079\tval-Gini:-0.345535\n",
      "[164]\ttrain-Gini:-0.457191\tval-Gini:-0.345370\n",
      "[165]\ttrain-Gini:-0.457334\tval-Gini:-0.345512\n",
      "[166]\ttrain-Gini:-0.457540\tval-Gini:-0.345699\n",
      "[167]\ttrain-Gini:-0.457518\tval-Gini:-0.345638\n",
      "[168]\ttrain-Gini:-0.457484\tval-Gini:-0.345590\n",
      "[169]\ttrain-Gini:-0.457686\tval-Gini:-0.345592\n",
      "[170]\ttrain-Gini:-0.457837\tval-Gini:-0.345607\n",
      "[171]\ttrain-Gini:-0.457909\tval-Gini:-0.345571\n",
      "[172]\ttrain-Gini:-0.457999\tval-Gini:-0.345423\n",
      "[173]\ttrain-Gini:-0.458226\tval-Gini:-0.345660\n",
      "[174]\ttrain-Gini:-0.458382\tval-Gini:-0.345757\n",
      "[175]\ttrain-Gini:-0.458529\tval-Gini:-0.345797\n",
      "[176]\ttrain-Gini:-0.458615\tval-Gini:-0.345878\n",
      "[177]\ttrain-Gini:-0.458934\tval-Gini:-0.346127\n",
      "[178]\ttrain-Gini:-0.459048\tval-Gini:-0.346089\n",
      "[179]\ttrain-Gini:-0.459230\tval-Gini:-0.346017\n",
      "[180]\ttrain-Gini:-0.459384\tval-Gini:-0.346138\n",
      "[181]\ttrain-Gini:-0.459511\tval-Gini:-0.345964\n",
      "[182]\ttrain-Gini:-0.459769\tval-Gini:-0.346213\n",
      "[183]\ttrain-Gini:-0.460058\tval-Gini:-0.346190\n",
      "[184]\ttrain-Gini:-0.460183\tval-Gini:-0.346340\n",
      "[185]\ttrain-Gini:-0.460360\tval-Gini:-0.346277\n",
      "[186]\ttrain-Gini:-0.460510\tval-Gini:-0.346365\n",
      "[187]\ttrain-Gini:-0.460657\tval-Gini:-0.346470\n",
      "[188]\ttrain-Gini:-0.460807\tval-Gini:-0.346596\n",
      "[189]\ttrain-Gini:-0.460868\tval-Gini:-0.346666\n",
      "[190]\ttrain-Gini:-0.461124\tval-Gini:-0.346776\n",
      "[191]\ttrain-Gini:-0.461387\tval-Gini:-0.346945\n",
      "[192]\ttrain-Gini:-0.461660\tval-Gini:-0.347149\n",
      "[193]\ttrain-Gini:-0.461649\tval-Gini:-0.347190\n",
      "[194]\ttrain-Gini:-0.461725\tval-Gini:-0.347086\n",
      "[195]\ttrain-Gini:-0.461883\tval-Gini:-0.347043\n",
      "[196]\ttrain-Gini:-0.462127\tval-Gini:-0.347121\n",
      "[197]\ttrain-Gini:-0.462430\tval-Gini:-0.347246\n",
      "[198]\ttrain-Gini:-0.462543\tval-Gini:-0.347506\n",
      "[199]\ttrain-Gini:-0.462674\tval-Gini:-0.347497\n",
      "[200]\ttrain-Gini:-0.462807\tval-Gini:-0.347528\n",
      "[201]\ttrain-Gini:-0.462972\tval-Gini:-0.347677\n",
      "[202]\ttrain-Gini:-0.463117\tval-Gini:-0.347722\n",
      "[203]\ttrain-Gini:-0.463290\tval-Gini:-0.347865\n",
      "[204]\ttrain-Gini:-0.463427\tval-Gini:-0.347846\n",
      "[205]\ttrain-Gini:-0.463505\tval-Gini:-0.347863\n",
      "[206]\ttrain-Gini:-0.463640\tval-Gini:-0.347998\n",
      "[207]\ttrain-Gini:-0.463763\tval-Gini:-0.347977\n",
      "[208]\ttrain-Gini:-0.463813\tval-Gini:-0.347992\n",
      "[209]\ttrain-Gini:-0.463929\tval-Gini:-0.348070\n",
      "[210]\ttrain-Gini:-0.464032\tval-Gini:-0.348153\n",
      "[211]\ttrain-Gini:-0.464098\tval-Gini:-0.347996\n",
      "[212]\ttrain-Gini:-0.464303\tval-Gini:-0.347944\n",
      "[213]\ttrain-Gini:-0.464504\tval-Gini:-0.348244\n",
      "[214]\ttrain-Gini:-0.464742\tval-Gini:-0.348134\n",
      "[215]\ttrain-Gini:-0.465000\tval-Gini:-0.348198\n",
      "[216]\ttrain-Gini:-0.465235\tval-Gini:-0.348221\n",
      "[217]\ttrain-Gini:-0.465335\tval-Gini:-0.348289\n",
      "[218]\ttrain-Gini:-0.465479\tval-Gini:-0.348385\n",
      "[219]\ttrain-Gini:-0.465676\tval-Gini:-0.348398\n",
      "[220]\ttrain-Gini:-0.465920\tval-Gini:-0.348551\n",
      "[221]\ttrain-Gini:-0.466023\tval-Gini:-0.348565\n",
      "[222]\ttrain-Gini:-0.466169\tval-Gini:-0.348690\n",
      "[223]\ttrain-Gini:-0.466353\tval-Gini:-0.348642\n",
      "[224]\ttrain-Gini:-0.466471\tval-Gini:-0.348642\n",
      "[225]\ttrain-Gini:-0.466710\tval-Gini:-0.348713\n",
      "[226]\ttrain-Gini:-0.466858\tval-Gini:-0.348827\n",
      "[227]\ttrain-Gini:-0.467077\tval-Gini:-0.348933\n",
      "[228]\ttrain-Gini:-0.467124\tval-Gini:-0.349115\n",
      "[229]\ttrain-Gini:-0.467250\tval-Gini:-0.349150\n",
      "[230]\ttrain-Gini:-0.467378\tval-Gini:-0.349170\n",
      "[231]\ttrain-Gini:-0.467586\tval-Gini:-0.349525\n",
      "[232]\ttrain-Gini:-0.467797\tval-Gini:-0.349660\n",
      "[233]\ttrain-Gini:-0.467852\tval-Gini:-0.349703\n",
      "[234]\ttrain-Gini:-0.468020\tval-Gini:-0.349700\n",
      "[235]\ttrain-Gini:-0.468029\tval-Gini:-0.349666\n",
      "[236]\ttrain-Gini:-0.468110\tval-Gini:-0.349608\n",
      "[237]\ttrain-Gini:-0.468316\tval-Gini:-0.349611\n",
      "[238]\ttrain-Gini:-0.468506\tval-Gini:-0.349473\n",
      "[239]\ttrain-Gini:-0.468650\tval-Gini:-0.349651\n",
      "[240]\ttrain-Gini:-0.468869\tval-Gini:-0.349636\n",
      "[241]\ttrain-Gini:-0.469052\tval-Gini:-0.349735\n",
      "[242]\ttrain-Gini:-0.469177\tval-Gini:-0.349890\n",
      "[243]\ttrain-Gini:-0.469300\tval-Gini:-0.349785\n",
      "[244]\ttrain-Gini:-0.469468\tval-Gini:-0.349889\n",
      "[245]\ttrain-Gini:-0.469600\tval-Gini:-0.349960\n",
      "[246]\ttrain-Gini:-0.469739\tval-Gini:-0.349894\n",
      "[247]\ttrain-Gini:-0.469808\tval-Gini:-0.349887\n",
      "[248]\ttrain-Gini:-0.470005\tval-Gini:-0.350091\n",
      "[249]\ttrain-Gini:-0.470134\tval-Gini:-0.350135\n",
      "[250]\ttrain-Gini:-0.470252\tval-Gini:-0.350156\n",
      "[251]\ttrain-Gini:-0.470408\tval-Gini:-0.350522\n",
      "[252]\ttrain-Gini:-0.470576\tval-Gini:-0.350525\n",
      "[253]\ttrain-Gini:-0.470729\tval-Gini:-0.350602\n",
      "[254]\ttrain-Gini:-0.470806\tval-Gini:-0.350540\n",
      "[255]\ttrain-Gini:-0.470961\tval-Gini:-0.350694\n",
      "[256]\ttrain-Gini:-0.471134\tval-Gini:-0.350748\n",
      "[257]\ttrain-Gini:-0.471222\tval-Gini:-0.350609\n",
      "[258]\ttrain-Gini:-0.471247\tval-Gini:-0.350534\n",
      "[259]\ttrain-Gini:-0.471378\tval-Gini:-0.350778\n",
      "[260]\ttrain-Gini:-0.471541\tval-Gini:-0.350807\n",
      "[261]\ttrain-Gini:-0.471581\tval-Gini:-0.350761\n",
      "[262]\ttrain-Gini:-0.471700\tval-Gini:-0.350794\n",
      "[263]\ttrain-Gini:-0.471842\tval-Gini:-0.350671\n",
      "[264]\ttrain-Gini:-0.472098\tval-Gini:-0.350704\n",
      "[265]\ttrain-Gini:-0.472238\tval-Gini:-0.350848\n",
      "[266]\ttrain-Gini:-0.472341\tval-Gini:-0.350751\n",
      "[267]\ttrain-Gini:-0.472424\tval-Gini:-0.350686\n",
      "[268]\ttrain-Gini:-0.472570\tval-Gini:-0.350541\n",
      "[269]\ttrain-Gini:-0.472773\tval-Gini:-0.350715\n",
      "[270]\ttrain-Gini:-0.472906\tval-Gini:-0.350913\n",
      "[271]\ttrain-Gini:-0.472987\tval-Gini:-0.350862\n",
      "[272]\ttrain-Gini:-0.473013\tval-Gini:-0.350836\n",
      "[273]\ttrain-Gini:-0.473125\tval-Gini:-0.350873\n",
      "[274]\ttrain-Gini:-0.473223\tval-Gini:-0.350882\n",
      "[275]\ttrain-Gini:-0.473381\tval-Gini:-0.350884\n",
      "[276]\ttrain-Gini:-0.473514\tval-Gini:-0.350850\n",
      "[277]\ttrain-Gini:-0.473808\tval-Gini:-0.350967\n",
      "[278]\ttrain-Gini:-0.474060\tval-Gini:-0.351041\n",
      "[279]\ttrain-Gini:-0.474235\tval-Gini:-0.351109\n",
      "[280]\ttrain-Gini:-0.474341\tval-Gini:-0.351059\n",
      "[281]\ttrain-Gini:-0.474468\tval-Gini:-0.351081\n",
      "[282]\ttrain-Gini:-0.474582\tval-Gini:-0.351208\n",
      "[283]\ttrain-Gini:-0.474631\tval-Gini:-0.351129\n",
      "[284]\ttrain-Gini:-0.474755\tval-Gini:-0.351202\n",
      "[285]\ttrain-Gini:-0.474969\tval-Gini:-0.351337\n",
      "[286]\ttrain-Gini:-0.475043\tval-Gini:-0.351301\n",
      "[287]\ttrain-Gini:-0.475164\tval-Gini:-0.351505\n",
      "[288]\ttrain-Gini:-0.475187\tval-Gini:-0.351476\n",
      "[289]\ttrain-Gini:-0.475302\tval-Gini:-0.351484\n",
      "[290]\ttrain-Gini:-0.475411\tval-Gini:-0.351295\n",
      "[291]\ttrain-Gini:-0.475620\tval-Gini:-0.351373\n",
      "[292]\ttrain-Gini:-0.475817\tval-Gini:-0.351409\n",
      "[293]\ttrain-Gini:-0.475901\tval-Gini:-0.351408\n",
      "[294]\ttrain-Gini:-0.476106\tval-Gini:-0.351397\n",
      "[295]\ttrain-Gini:-0.476261\tval-Gini:-0.351554\n",
      "[296]\ttrain-Gini:-0.476404\tval-Gini:-0.351490\n",
      "[297]\ttrain-Gini:-0.476545\tval-Gini:-0.351378\n",
      "[298]\ttrain-Gini:-0.476633\tval-Gini:-0.351637\n",
      "[299]\ttrain-Gini:-0.476719\tval-Gini:-0.351708\n",
      "[300]\ttrain-Gini:-0.476942\tval-Gini:-0.351681\n",
      "[301]\ttrain-Gini:-0.477201\tval-Gini:-0.351828\n",
      "[302]\ttrain-Gini:-0.477343\tval-Gini:-0.351896\n",
      "[303]\ttrain-Gini:-0.477597\tval-Gini:-0.351915\n",
      "[304]\ttrain-Gini:-0.477655\tval-Gini:-0.351817\n",
      "[305]\ttrain-Gini:-0.477825\tval-Gini:-0.352034\n",
      "[306]\ttrain-Gini:-0.477927\tval-Gini:-0.351978\n",
      "[307]\ttrain-Gini:-0.478027\tval-Gini:-0.352015\n",
      "[308]\ttrain-Gini:-0.478127\tval-Gini:-0.352023\n",
      "[309]\ttrain-Gini:-0.478245\tval-Gini:-0.351991\n",
      "[310]\ttrain-Gini:-0.478314\tval-Gini:-0.351985\n",
      "[311]\ttrain-Gini:-0.478487\tval-Gini:-0.352011\n",
      "[312]\ttrain-Gini:-0.478656\tval-Gini:-0.351979\n",
      "[313]\ttrain-Gini:-0.478868\tval-Gini:-0.352062\n",
      "[314]\ttrain-Gini:-0.478905\tval-Gini:-0.351981\n",
      "[315]\ttrain-Gini:-0.479039\tval-Gini:-0.352089\n",
      "[316]\ttrain-Gini:-0.479226\tval-Gini:-0.352141\n",
      "[317]\ttrain-Gini:-0.479289\tval-Gini:-0.352201\n",
      "[318]\ttrain-Gini:-0.479353\tval-Gini:-0.352236\n",
      "[319]\ttrain-Gini:-0.479406\tval-Gini:-0.352230\n",
      "[320]\ttrain-Gini:-0.479514\tval-Gini:-0.352371\n",
      "[321]\ttrain-Gini:-0.479603\tval-Gini:-0.352372\n",
      "[322]\ttrain-Gini:-0.479763\tval-Gini:-0.352462\n",
      "[323]\ttrain-Gini:-0.479950\tval-Gini:-0.352577\n",
      "[324]\ttrain-Gini:-0.480079\tval-Gini:-0.352576\n",
      "[325]\ttrain-Gini:-0.480232\tval-Gini:-0.352566\n",
      "[326]\ttrain-Gini:-0.480487\tval-Gini:-0.352581\n",
      "[327]\ttrain-Gini:-0.480685\tval-Gini:-0.352716\n",
      "[328]\ttrain-Gini:-0.480825\tval-Gini:-0.352823\n",
      "[329]\ttrain-Gini:-0.480914\tval-Gini:-0.352767\n",
      "[330]\ttrain-Gini:-0.481065\tval-Gini:-0.352769\n",
      "[331]\ttrain-Gini:-0.481108\tval-Gini:-0.352750\n",
      "[332]\ttrain-Gini:-0.481269\tval-Gini:-0.352759\n",
      "[333]\ttrain-Gini:-0.481365\tval-Gini:-0.352821\n",
      "[334]\ttrain-Gini:-0.481403\tval-Gini:-0.352803\n",
      "[335]\ttrain-Gini:-0.481519\tval-Gini:-0.352877\n",
      "[336]\ttrain-Gini:-0.481664\tval-Gini:-0.352954\n",
      "[337]\ttrain-Gini:-0.481815\tval-Gini:-0.352911\n",
      "[338]\ttrain-Gini:-0.481969\tval-Gini:-0.353088\n",
      "[339]\ttrain-Gini:-0.482085\tval-Gini:-0.353241\n",
      "[340]\ttrain-Gini:-0.482246\tval-Gini:-0.353309\n",
      "[341]\ttrain-Gini:-0.482357\tval-Gini:-0.353331\n",
      "[342]\ttrain-Gini:-0.482416\tval-Gini:-0.353302\n",
      "[343]\ttrain-Gini:-0.482549\tval-Gini:-0.353440\n",
      "[344]\ttrain-Gini:-0.482676\tval-Gini:-0.353456\n",
      "[345]\ttrain-Gini:-0.482800\tval-Gini:-0.353329\n",
      "[346]\ttrain-Gini:-0.482942\tval-Gini:-0.353453\n",
      "[347]\ttrain-Gini:-0.483020\tval-Gini:-0.353516\n",
      "[348]\ttrain-Gini:-0.483112\tval-Gini:-0.353609\n",
      "[349]\ttrain-Gini:-0.483248\tval-Gini:-0.353694\n",
      "[350]\ttrain-Gini:-0.483363\tval-Gini:-0.353664\n",
      "[351]\ttrain-Gini:-0.483454\tval-Gini:-0.353592\n",
      "[352]\ttrain-Gini:-0.483576\tval-Gini:-0.353633\n",
      "[353]\ttrain-Gini:-0.483639\tval-Gini:-0.353671\n",
      "[354]\ttrain-Gini:-0.483702\tval-Gini:-0.353557\n",
      "[355]\ttrain-Gini:-0.483950\tval-Gini:-0.353785\n",
      "[356]\ttrain-Gini:-0.484047\tval-Gini:-0.353732\n",
      "[357]\ttrain-Gini:-0.484295\tval-Gini:-0.353931\n",
      "[358]\ttrain-Gini:-0.484369\tval-Gini:-0.353977\n",
      "[359]\ttrain-Gini:-0.484559\tval-Gini:-0.354006\n",
      "[360]\ttrain-Gini:-0.484705\tval-Gini:-0.353913\n",
      "[361]\ttrain-Gini:-0.484772\tval-Gini:-0.353919\n",
      "[362]\ttrain-Gini:-0.484910\tval-Gini:-0.353918\n",
      "[363]\ttrain-Gini:-0.485040\tval-Gini:-0.354078\n",
      "[364]\ttrain-Gini:-0.485305\tval-Gini:-0.354297\n",
      "[365]\ttrain-Gini:-0.485362\tval-Gini:-0.354164\n",
      "[366]\ttrain-Gini:-0.485510\tval-Gini:-0.354264\n",
      "[367]\ttrain-Gini:-0.485696\tval-Gini:-0.354434\n",
      "[368]\ttrain-Gini:-0.485881\tval-Gini:-0.354460\n",
      "[369]\ttrain-Gini:-0.486020\tval-Gini:-0.354501\n",
      "[370]\ttrain-Gini:-0.486073\tval-Gini:-0.354453\n",
      "[371]\ttrain-Gini:-0.486182\tval-Gini:-0.354590\n",
      "[372]\ttrain-Gini:-0.486327\tval-Gini:-0.354579\n",
      "[373]\ttrain-Gini:-0.486402\tval-Gini:-0.354672\n",
      "[374]\ttrain-Gini:-0.486519\tval-Gini:-0.354785\n",
      "[375]\ttrain-Gini:-0.486655\tval-Gini:-0.354823\n",
      "[376]\ttrain-Gini:-0.486697\tval-Gini:-0.354873\n",
      "[377]\ttrain-Gini:-0.486830\tval-Gini:-0.354747\n",
      "[378]\ttrain-Gini:-0.486882\tval-Gini:-0.354731\n",
      "[379]\ttrain-Gini:-0.487034\tval-Gini:-0.354836\n",
      "[380]\ttrain-Gini:-0.487187\tval-Gini:-0.354833\n",
      "[381]\ttrain-Gini:-0.487344\tval-Gini:-0.354898\n",
      "[382]\ttrain-Gini:-0.487420\tval-Gini:-0.354948\n",
      "[383]\ttrain-Gini:-0.487566\tval-Gini:-0.355007\n",
      "[384]\ttrain-Gini:-0.487753\tval-Gini:-0.355114\n",
      "[385]\ttrain-Gini:-0.487884\tval-Gini:-0.355120\n",
      "[386]\ttrain-Gini:-0.488147\tval-Gini:-0.355196\n",
      "[387]\ttrain-Gini:-0.488345\tval-Gini:-0.355160\n",
      "[388]\ttrain-Gini:-0.488529\tval-Gini:-0.355234\n",
      "[389]\ttrain-Gini:-0.488696\tval-Gini:-0.355257\n",
      "[390]\ttrain-Gini:-0.488813\tval-Gini:-0.355281\n",
      "[391]\ttrain-Gini:-0.488919\tval-Gini:-0.355389\n",
      "[392]\ttrain-Gini:-0.489115\tval-Gini:-0.355502\n",
      "[393]\ttrain-Gini:-0.489176\tval-Gini:-0.355520\n",
      "[394]\ttrain-Gini:-0.489239\tval-Gini:-0.355521\n",
      "[395]\ttrain-Gini:-0.489335\tval-Gini:-0.355525\n",
      "[396]\ttrain-Gini:-0.489485\tval-Gini:-0.355630\n",
      "[397]\ttrain-Gini:-0.489592\tval-Gini:-0.355667\n",
      "[398]\ttrain-Gini:-0.489732\tval-Gini:-0.355788\n",
      "[399]\ttrain-Gini:-0.489847\tval-Gini:-0.355768\n",
      "[400]\ttrain-Gini:-0.490045\tval-Gini:-0.355703\n",
      "[401]\ttrain-Gini:-0.490155\tval-Gini:-0.355704\n",
      "[402]\ttrain-Gini:-0.490222\tval-Gini:-0.355602\n",
      "[403]\ttrain-Gini:-0.490347\tval-Gini:-0.355587\n",
      "[404]\ttrain-Gini:-0.490528\tval-Gini:-0.355819\n",
      "[405]\ttrain-Gini:-0.490625\tval-Gini:-0.355787\n",
      "[406]\ttrain-Gini:-0.490708\tval-Gini:-0.355832\n",
      "[407]\ttrain-Gini:-0.490812\tval-Gini:-0.355877\n",
      "[408]\ttrain-Gini:-0.490895\tval-Gini:-0.355969\n",
      "[409]\ttrain-Gini:-0.491074\tval-Gini:-0.356035\n",
      "[410]\ttrain-Gini:-0.491195\tval-Gini:-0.356083\n",
      "[411]\ttrain-Gini:-0.491334\tval-Gini:-0.356083\n",
      "[412]\ttrain-Gini:-0.491340\tval-Gini:-0.356061\n"
     ]
    }
   ],
   "source": [
    "preds1 = xgboost_pred(train_s,labels,test_s)\n",
    "\n",
    "#model_2 building\n",
    "\n",
    "train = train.T.to_dict().values()\n",
    "test = test.T.to_dict().values()\n",
    "\n",
    "vec = DictVectorizer()\n",
    "train = vec.fit_transform(train)\n",
    "test = vec.transform(test)\n",
    "\n",
    "preds2 = xgboost_pred(train,labels,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in np.linspace(.2,.8,4):\n",
    "    preds = p * (preds1**0.2) + (1-p) * (preds2**0.8)\n",
    "    preds = pd.DataFrame({\"Id\": test_ind, \"Hazard\": preds})\n",
    "    preds = preds.set_index('Id')\n",
    "    preds.to_csv('sub'+str(p)+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
